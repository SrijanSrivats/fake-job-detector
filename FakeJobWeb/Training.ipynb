{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9840258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_job_prediction_full.R\n",
    "# Complete, fixed version of Fake Job Prediction pipeline using XGBoost + caret\n",
    "# Requirements: install packages listed below (run once)\n",
    "# install.packages(c(\"tm\",\"tidyverse\",\"caret\",\"randomForest\",\"e1071\",\"xgboost\",\n",
    "#                    \"rpart\",\"rpart.plot\",\"pROC\",\"ROSE\",\"corrplot\",\"ggplot2\",\n",
    "#                    \"ggthemes\",\"stringr\",\"SnowballC\",\"wordcloud\",\"textmineR\",\n",
    "#                    \"Matrix\",\"kernlab\"))\n",
    "\n",
    "# Load libraries\n",
    "library(tm)\n",
    "library(tidyverse)\n",
    "library(caret)\n",
    "library(randomForest)\n",
    "library(e1071)\n",
    "library(xgboost)\n",
    "library(rpart)\n",
    "library(rpart.plot)\n",
    "library(pROC)\n",
    "library(ROSE)\n",
    "library(corrplot)\n",
    "library(ggplot2)\n",
    "library(ggthemes)\n",
    "library(stringr)\n",
    "library(SnowballC)\n",
    "library(wordcloud)\n",
    "library(textmineR)\n",
    "library(Matrix)\n",
    "library(kernlab)\n",
    "\n",
    "set.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48389085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "dir.create(\"visualizations\", showWarnings = FALSE)\n",
    "dir.create(\"models\", showWarnings = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cadabb5",
   "metadata": {},
   "source": [
    "# -------------------------\n",
    "# 1. LOAD DATA\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43a97f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dimensions: 17880 18 \n",
      "Column Names: job_id, title, location, department, salary_range, company_profile, description, requirements, benefits, telecommuting, has_company_logo, has_questions, employment_type, required_experience, required_education, industry, function., fraudulent \n"
     ]
    }
   ],
   "source": [
    "data_path <- \"fake_job_postings.csv\"\n",
    "if (!file.exists(data_path)) stop(paste(\"Dataset not found at\", data_path))\n",
    "data <- read.csv(data_path, stringsAsFactors = FALSE, na.strings = c(\"\", \"NA\"))\n",
    "\n",
    "cat(\"Dataset Dimensions:\", dim(data), \"\\n\")\n",
    "cat(\"Column Names:\", paste(names(data), collapse = \", \"), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d7a65f",
   "metadata": {},
   "source": [
    "# -------------------------\n",
    "# 2. INITIAL CLEANING & MISSING HANDLING\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "497367a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure column names are syntactically valid\n",
    "names(data) <- make.names(names(data))\n",
    "\n",
    "# Convert fraudulent to factor early (ensure it exists)\n",
    "if (!\"fraudulent\" %in% names(data)) stop(\"Dataset must contain column named 'fraudulent'\")\n",
    "data$fraudulent <- as.integer(data$fraudulent) # ensure numeric 0/1\n",
    "data$fraudulent[is.na(data$fraudulent)] <- 0\n",
    "data$fraudulent <- factor(data$fraudulent, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\n",
    "\n",
    "# Handle missing / blank text columns\n",
    "text_cols <- c(\"title\",\"location\",\"department\",\"company_profile\",\"description\",\n",
    "               \"requirements\",\"benefits\",\"employment_type\",\"required_experience\",\n",
    "               \"required_education\",\"industry\",\"function.\")\n",
    "for (col in intersect(text_cols, names(data))) {\n",
    "  data[[col]][is.na(data[[col]])] <- \"\"\n",
    "}\n",
    "\n",
    "# Numeric binary fields: telecommuting, has_company_logo, has_questions\n",
    "for (col in c(\"telecommuting\",\"has_company_logo\",\"has_questions\")) {\n",
    "  if (col %in% names(data)) {\n",
    "    data[[col]] <- as.integer(replace(data[[col]], is.na(data[[col]]), 0))\n",
    "  } else {\n",
    "    data[[col]] <- 0L\n",
    "  }\n",
    "}\n",
    "\n",
    "# Remove duplicates\n",
    "data <- data[!duplicated(data), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b719e4",
   "metadata": {},
   "source": [
    "# -------------------------\n",
    "# 3. FEATURE ENGINEERING\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94a28e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text columns (this may take a moment)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"Removing near-zero variance columns: telecommuting, salary_keywords\"\n"
     ]
    }
   ],
   "source": [
    "# Add simple text-length features and keyword counts\n",
    "data <- data %>%\n",
    "  mutate(\n",
    "    desc_length = nchar(description),\n",
    "    req_length = nchar(requirements),\n",
    "    benefits_length = nchar(benefits),\n",
    "    company_profile_length = nchar(company_profile),\n",
    "    title_length = nchar(title),\n",
    "    # basic keyword signals\n",
    "    salary_keywords = str_count(tolower(paste(description, requirements, benefits, sep = \" \")),\n",
    "                               \"unpaid|volunteer|no salary|commission only|paid after\"),\n",
    "    urgency_keywords = str_count(tolower(paste(description, requirements, sep = \" \")),\n",
    "                                 \"immediate|urgent|quick|start now|apply now|ASAP\")\n",
    "  )\n",
    "\n",
    "# winsorize function for numeric columns\n",
    "handle_outliers <- function(x) {\n",
    "  if (!is.numeric(x)) return(x)\n",
    "  q1 <- quantile(x, 0.25, na.rm = TRUE)\n",
    "  q3 <- quantile(x, 0.75, na.rm = TRUE)\n",
    "  iqr <- q3 - q1\n",
    "  lower_bound <- q1 - 1.5 * iqr\n",
    "  upper_bound <- q3 + 1.5 * iqr\n",
    "  x[x < lower_bound] <- lower_bound\n",
    "  x[x > upper_bound] <- upper_bound\n",
    "  return(x)\n",
    "}\n",
    "\n",
    "numeric_cols_to_trim <- c(\"desc_length\",\"req_length\",\"benefits_length\",\"company_profile_length\",\"title_length\")\n",
    "for (col in numeric_cols_to_trim) {\n",
    "  if (col %in% names(data)) data[[col]] <- handle_outliers(data[[col]])\n",
    "}\n",
    "\n",
    "# Text preprocessing helper\n",
    "preprocess_text <- function(text) {\n",
    "  if (is.na(text) || text == \"\") return(\"\")\n",
    "  text <- tolower(text)\n",
    "  text <- removePunctuation(text)\n",
    "  text <- removeNumbers(text)\n",
    "  text <- removeWords(text, stopwords(\"english\"))\n",
    "  text <- stripWhitespace(text)\n",
    "  text <- trimws(text)\n",
    "  return(text)\n",
    "}\n",
    "\n",
    "cat(\"Preprocessing text columns (this may take a moment)...\\n\")\n",
    "data$description_clean <- vapply(data$description, preprocess_text, FUN.VALUE = \"\")\n",
    "data$requirements_clean <- vapply(data$requirements, preprocess_text, FUN.VALUE = \"\")\n",
    "\n",
    "# Function to create simple text-derived numeric features\n",
    "create_text_features <- function(texts, prefix) {\n",
    "  fake_keywords <- c(\"money\",\"cash\",\"quick\",\"easy\",\"guarantee\",\"free\",\n",
    "                     \"profit\",\"income\",\"rich\",\"wealth\",\"million\",\"billion\",\n",
    "                     \"immediate\",\"urgent\",\"commission\")\n",
    "  \n",
    "  # Each vapply call should return a single integer per row â†’ use integer(1)\n",
    "  word_count <- vapply(texts, function(x) {\n",
    "    if (is.na(x) || x == \"\") return(0L)\n",
    "    w <- unlist(strsplit(x, \"\\\\s+\"))\n",
    "    w <- w[w != \"\"]\n",
    "    length(w)\n",
    "  }, integer(1))\n",
    "  \n",
    "  char_count <- nchar(texts)\n",
    "  avg_word_length <- ifelse(word_count > 0, char_count / word_count, 0)\n",
    "  \n",
    "  keyword_counts <- vapply(texts, function(txt) {\n",
    "    if (is.na(txt) || txt == \"\") return(0L)\n",
    "    sum(vapply(fake_keywords, function(k) str_count(txt, fixed(k)), integer(1)))\n",
    "  }, integer(1))\n",
    "  \n",
    "  df <- data.frame(\n",
    "    word_count = word_count,\n",
    "    char_count = char_count,\n",
    "    avg_word_length = avg_word_length,\n",
    "    keyword_counts = keyword_counts\n",
    "  )\n",
    "  colnames(df) <- paste0(prefix, c(\"_word_count\", \"_char_count\", \"_avg_word_length\", \"_fake_keywords\"))\n",
    "  return(df)\n",
    "}\n",
    "\n",
    "desc_feats <- create_text_features(data$description_clean, \"desc\")\n",
    "req_feats <- create_text_features(data$requirements_clean, \"req\")\n",
    "\n",
    "# Combine features\n",
    "essential_features <- data %>%\n",
    "  transmute(\n",
    "    telecommuting = telecommuting,\n",
    "    has_company_logo = has_company_logo,\n",
    "    has_questions = has_questions,\n",
    "    desc_length = desc_length,\n",
    "    req_length = req_length,\n",
    "    benefits_length = benefits_length,\n",
    "    company_profile_length = company_profile_length,\n",
    "    title_length = title_length,\n",
    "    salary_keywords = salary_keywords,\n",
    "    urgency_keywords = urgency_keywords\n",
    "  )\n",
    "\n",
    "final_features <- cbind(essential_features, desc_feats, req_feats)\n",
    "final_data <- as.data.frame(final_features)\n",
    "final_data$fraudulent <- data$fraudulent  # ensure target exists in final_data\n",
    "\n",
    "# Remove near-zero variance features if any\n",
    "nzv <- nearZeroVar(final_data[, setdiff(names(final_data), \"fraudulent\")], saveMetrics = FALSE)\n",
    "if (length(nzv) > 0) {\n",
    "  warning(\"Removing near-zero variance columns: \", paste(names(final_data)[nzv], collapse = \", \"))\n",
    "  final_data <- final_data[, setdiff(names(final_data), names(final_data)[nzv]), drop = FALSE]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ff109",
   "metadata": {},
   "source": [
    "# -------------------------\n",
    "# 4. DATA QUALITY CHECK\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b022d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Data Quality Check: Final features (before sampling) --\n",
      "Dimensions: 17880 17 \n",
      "NA count: 0 \n",
      "Target distribution:\n",
      "\n",
      "   No   Yes \n",
      "17014   866 \n",
      "\n",
      "    No    Yes \n",
      "0.9516 0.0484 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "check_data_quality <- function(df, name) {\n",
    "  cat(\"\\n-- Data Quality Check:\", name, \"--\\n\")\n",
    "  cat(\"Dimensions:\", dim(df), \"\\n\")\n",
    "  cat(\"NA count:\", sum(is.na(df)), \"\\n\")\n",
    "  cat(\"Target distribution:\\n\")\n",
    "  print(table(df$fraudulent))\n",
    "  print(round(prop.table(table(df$fraudulent)), 4))\n",
    "}\n",
    "check_data_quality(final_data, \"Final features (before sampling)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a9ad83",
   "metadata": {},
   "source": [
    "# -------------------------\n",
    "# 5. HANDLE CLASS IMBALANCE (ROSE)\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88e4a41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying ROSE to balance classes...\n",
      "\n",
      "-- Data Quality Check: After ROSE balancing --\n",
      "Dimensions: 17880 17 \n",
      "NA count: 0 \n",
      "Target distribution:\n",
      "\n",
      "  No  Yes \n",
      "9051 8829 \n",
      "\n",
      "    No    Yes \n",
      "0.5062 0.4938 \n"
     ]
    }
   ],
   "source": [
    "cat(\"\\nApplying ROSE to balance classes...\\n\")\n",
    "# ovun.sample wants formula; ensure fraudulent exists as factor in final_data\n",
    "final_data$fraudulent <- factor(final_data$fraudulent, levels = c(\"No\",\"Yes\"))\n",
    "\n",
    "balanced_obj <- ovun.sample(fraudulent ~ ., data = final_data, method = \"both\", p = 0.5, seed = 123)\n",
    "final_data_balanced <- balanced_obj$data\n",
    "check_data_quality(final_data_balanced, \"After ROSE balancing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308afd07",
   "metadata": {},
   "source": [
    "# -------------------------\n",
    "# 6. VISUALIZATIONS (basic)\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a312e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 <- ggplot(final_data_balanced, aes(x = fraudulent, fill = fraudulent)) +\n",
    "  geom_bar() + labs(title = \"Class Distribution After ROSE\", x = \"Fraudulent\", y = \"Count\") +\n",
    "  theme_minimal()\n",
    "ggsave(\"visualizations/class_distribution.png\", p1, width = 7, height = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6326cbb",
   "metadata": {},
   "source": [
    "# -------------------------\n",
    "# 7. TRAIN/TEST SPLIT and SCALING\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9aedd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimensions: 14305 17 Test dimensions: 3575 17 \n"
     ]
    }
   ],
   "source": [
    "set.seed(123)\n",
    "train_index <- createDataPartition(final_data_balanced$fraudulent, p = 0.8, list = FALSE)\n",
    "train_data <- final_data_balanced[train_index, , drop = FALSE]\n",
    "test_data <- final_data_balanced[-train_index, , drop = FALSE]\n",
    "\n",
    "cat(\"Train dimensions:\", dim(train_data), \"Test dimensions:\", dim(test_data), \"\\n\")\n",
    "\n",
    "# Preprocess numeric predictors (center & scale) - exclude target\n",
    "predictor_names <- setdiff(colnames(train_data), \"fraudulent\")\n",
    "preproc <- preProcess(train_data[, predictor_names], method = c(\"center\", \"scale\"))\n",
    "train_scaled <- train_data\n",
    "train_scaled[, predictor_names] <- predict(preproc, train_data[, predictor_names])\n",
    "test_scaled <- test_data\n",
    "test_scaled[, predictor_names] <- predict(preproc, test_data[, predictor_names])\n",
    "\n",
    "# Ensure factors are correct for caret\n",
    "train_scaled$fraudulent <- factor(train_scaled$fraudulent, levels = c(\"No\", \"Yes\"))\n",
    "test_scaled$fraudulent <- factor(test_scaled$fraudulent, levels = c(\"No\", \"Yes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fe69400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved to models/preproc_scaler.rds\n"
     ]
    }
   ],
   "source": [
    "saveRDS(preproc, \"models/preproc_scaler.rds\")\n",
    "cat(\"Scaler saved to models/preproc_scaler.rds\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ef4a88",
   "metadata": {},
   "source": [
    "# -------------------------\n",
    "# 8. MODEL TRAINING (XGBoost via caret)\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed942096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model (may take a minute)...\n",
      "+ Fold1: nrounds=100, max_depth=6, eta=0.3, gamma=0, colsample_bytree=0.8, min_child_weight=1, subsample=0.8 \n",
      "- Fold1: nrounds=100, max_depth=6, eta=0.3, gamma=0, colsample_bytree=0.8, min_child_weight=1, subsample=0.8 \n",
      "+ Fold2: nrounds=100, max_depth=6, eta=0.3, gamma=0, colsample_bytree=0.8, min_child_weight=1, subsample=0.8 \n",
      "- Fold2: nrounds=100, max_depth=6, eta=0.3, gamma=0, colsample_bytree=0.8, min_child_weight=1, subsample=0.8 \n",
      "+ Fold3: nrounds=100, max_depth=6, eta=0.3, gamma=0, colsample_bytree=0.8, min_child_weight=1, subsample=0.8 \n",
      "- Fold3: nrounds=100, max_depth=6, eta=0.3, gamma=0, colsample_bytree=0.8, min_child_weight=1, subsample=0.8 \n",
      "Aggregating results\n",
      "Fitting final model on full training set\n",
      "Model saved to models/xgboost_model.rds\n"
     ]
    }
   ],
   "source": [
    "train_control <- trainControl(\n",
    "  method = \"cv\",\n",
    "  number = 3,\n",
    "  classProbs = TRUE,\n",
    "  summaryFunction = twoClassSummary,\n",
    "  verboseIter = TRUE,\n",
    "  allowParallel = TRUE\n",
    ")\n",
    "\n",
    "# A small grid\n",
    "xgb_grid <- expand.grid(\n",
    "  nrounds = 100,\n",
    "  max_depth = 6,\n",
    "  eta = 0.3,\n",
    "  gamma = 0,\n",
    "  colsample_bytree = 0.8,\n",
    "  min_child_weight = 1,\n",
    "  subsample = 0.8\n",
    ")\n",
    "\n",
    "cat(\"Training XGBoost model (may take a minute)...\\n\")\n",
    "set.seed(123)\n",
    "xgb_model <- train(\n",
    "  x = train_scaled[, predictor_names],\n",
    "  y = train_scaled$fraudulent,\n",
    "  method = \"xgbTree\",\n",
    "  trControl = train_control,\n",
    "  tuneGrid = xgb_grid,\n",
    "  metric = \"ROC\",\n",
    "  verbosity = 0\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "saveRDS(xgb_model, file = \"models/xgboost_model.rds\")\n",
    "cat(\"Model saved to models/xgboost_model.rds\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec0bd7",
   "metadata": {},
   "source": [
    "# -------------------------\n",
    "# 9. EVALUATION\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb6689f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = 0, case = 1\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL PERFORMANCE ===\n",
      "Accuracy: 0.9855 \n",
      "Precision: 0.9724 \n",
      "Recall: 0.9989 \n",
      "F1: 0.9855 \n",
      "AUC: 0.9996 \n",
      "Confusion Matrix:\n",
      "          Reference\n",
      "Prediction   No  Yes\n",
      "       No  1760    2\n",
      "       Yes   50 1763\n",
      "     Metric  Value\n",
      "1  Accuracy 0.9855\n",
      "2 Precision 0.9724\n",
      "3    Recall 0.9989\n",
      "4  F1-Score 0.9855\n",
      "5       AUC 0.9996\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>agg_record_1814656817:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{agg\\textbackslash{}\\_record\\textbackslash{}\\_1814656817:} 2"
      ],
      "text/markdown": [
       "**agg_record_1814656817:** 2"
      ],
      "text/plain": [
       "agg_record_1814656817 \n",
       "                    2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PIPELINE COMPLETED SUCCESSFULLY ===\n",
      "Visualizations saved in 'visualizations/' and model saved in 'models/'.\n"
     ]
    }
   ],
   "source": [
    "preds <- predict(xgb_model, test_scaled[, predictor_names])\n",
    "probs <- predict(xgb_model, test_scaled[, predictor_names], type = \"prob\")\n",
    "\n",
    "conf <- confusionMatrix(preds, test_scaled$fraudulent, positive = \"Yes\")\n",
    "accuracy <- conf$overall[\"Accuracy\"]\n",
    "precision <- conf$byClass[\"Precision\"]\n",
    "recall <- conf$byClass[\"Recall\"]\n",
    "f1 <- conf$byClass[\"F1\"]\n",
    "\n",
    "# AUC\n",
    "roc_obj <- roc(response = ifelse(test_scaled$fraudulent == \"Yes\", 1, 0), predictor = probs[, \"Yes\"])\n",
    "auc_value <- as.numeric(auc(roc_obj))\n",
    "\n",
    "cat(\"\\n=== MODEL PERFORMANCE ===\\n\")\n",
    "cat(\"Accuracy:\", round(accuracy, 4), \"\\n\")\n",
    "cat(\"Precision:\", round(precision, 4), \"\\n\")\n",
    "cat(\"Recall:\", round(recall, 4), \"\\n\")\n",
    "cat(\"F1:\", round(f1, 4), \"\\n\")\n",
    "cat(\"AUC:\", round(auc_value, 4), \"\\n\")\n",
    "cat(\"Confusion Matrix:\\n\")\n",
    "print(conf$table)\n",
    "\n",
    "# Save performance table\n",
    "results_summary <- data.frame(\n",
    "  Metric = c(\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"AUC\"),\n",
    "  Value = c(round(as.numeric(accuracy), 4),\n",
    "            round(as.numeric(precision), 4),\n",
    "            round(as.numeric(recall), 4),\n",
    "            round(as.numeric(f1), 4),\n",
    "            round(auc_value, 4))\n",
    ")\n",
    "write.csv(results_summary, \"visualizations/model_performance.csv\", row.names = FALSE)\n",
    "print(results_summary)\n",
    "\n",
    "# ROC plot saved\n",
    "png(\"visualizations/roc_curve.png\", width = 800, height = 600)\n",
    "plot(roc_obj, main = paste0(\"ROC Curve - XGBoost (AUC=\", round(auc_value, 4), \")\"))\n",
    "dev.off()\n",
    "\n",
    "# Feature importance from final model\n",
    "if (!is.null(xgb_model$finalModel)) {\n",
    "  importance_matrix <- xgb.importance(feature_names = predictor_names, model = xgb_model$finalModel)\n",
    "  if (nrow(importance_matrix) > 0) {\n",
    "    topN <- min(10, nrow(importance_matrix))\n",
    "    top_features <- importance_matrix[1:topN, ]\n",
    "    p_imp <- ggplot(top_features, aes(x=reorder(Feature, Gain), y=Gain)) +\n",
    "      geom_col() + coord_flip() + labs(title = \"XGBoost Feature Importance (Gain)\", x = \"Feature\", y = \"Gain\") +\n",
    "      theme_minimal()\n",
    "    ggsave(\"visualizations/xgb_feature_importance.png\", p_imp, width = 9, height = 6)\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"\\n=== PIPELINE COMPLETED SUCCESSFULLY ===\\n\")\n",
    "cat(\"Visualizations saved in 'visualizations/' and model saved in 'models/'.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "132176be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Batch Prediction on full dataset ===\n",
      "âœ… Preprocessing scaler loaded.\n",
      "\n",
      "ðŸŽ‰ Batch Prediction Completed!\n",
      "ðŸ“ Saved: predictions_all_records.csv\n",
      "ðŸ“ Saved: predictions_fake_only.csv\n",
      "ðŸ“ Saved: predictions_genuine_only.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#                ðŸ”„ BATCH PREDICTION (FULL DATASET)\n",
    "# ============================================================\n",
    "\n",
    "cat(\"\\n=== Running Batch Prediction on full dataset ===\\n\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# 1. Load the preprocessing scaler (saved earlier)\n",
    "# -------------------------------------------\n",
    "preproc_path <- \"models/preproc_scaler.rds\"\n",
    "if (!file.exists(preproc_path)) {\n",
    "  stop(\"âŒ Missing scaler file: models/preproc_scaler.rds. \n",
    "       Please save using: saveRDS(preproc, 'models/preproc_scaler.rds')\")\n",
    "}\n",
    "preproc <- readRDS(preproc_path)\n",
    "\n",
    "cat(\"âœ… Preprocessing scaler loaded.\\n\")\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# 2. Load the original dataset again\n",
    "# -------------------------------------------\n",
    "batch_data <- read.csv(\"fake_job_postings.csv\", \n",
    "                       stringsAsFactors = FALSE, na.strings = c(\"\", \"NA\"))\n",
    "\n",
    "# Only keep frontend fields\n",
    "frontend_fields <- c(\n",
    "  \"title\", \"description\", \"requirements\", \"benefits\", \"company_profile\",\n",
    "  \"telecommuting\", \"has_company_logo\", \"has_questions\"\n",
    ")\n",
    "\n",
    "# Add missing frontend fields if absent\n",
    "for (f in frontend_fields) {\n",
    "  if (!f %in% names(batch_data)) batch_data[[f]] <- \"\"\n",
    "  batch_data[[f]][is.na(batch_data[[f]])] <- \n",
    "    ifelse(f %in% c(\"telecommuting\",\"has_company_logo\",\"has_questions\"), 0, \"\")\n",
    "}\n",
    "\n",
    "batch_data$telecommuting    <- as.integer(batch_data$telecommuting)\n",
    "batch_data$has_company_logo <- as.integer(batch_data$has_company_logo)\n",
    "batch_data$has_questions    <- as.integer(batch_data$has_questions)\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# 3. Apply SAME FEATURE ENGINEERING used in training\n",
    "# -------------------------------------------\n",
    "\n",
    "# prepare_features_batch() uses:\n",
    "# preprocess_text()\n",
    "# create_text_features()\n",
    "# and your engineered fields\n",
    "prepare_features_batch <- function(df) {\n",
    "\n",
    "  df$description_clean  <- vapply(df$description, preprocess_text, FUN.VALUE = \"\")\n",
    "  df$requirements_clean <- vapply(df$requirements, preprocess_text, FUN.VALUE = \"\")\n",
    "\n",
    "  desc_feats <- create_text_features(df$description_clean, \"desc\")\n",
    "  req_feats  <- create_text_features(df$requirements_clean, \"req\")\n",
    "\n",
    "  essential <- df %>% mutate(\n",
    "    desc_length             = nchar(description),\n",
    "    req_length              = nchar(requirements),\n",
    "    benefits_length         = nchar(benefits),\n",
    "    company_profile_length  = nchar(company_profile),\n",
    "    title_length            = nchar(title),\n",
    "    salary_keywords = str_count(\n",
    "      tolower(paste(description, requirements, benefits)),\n",
    "      \"unpaid|volunteer|no salary|commission only|paid after\"\n",
    "    ),\n",
    "    urgency_keywords = str_count(\n",
    "      tolower(paste(description, requirements)),\n",
    "      \"immediate|urgent|quick|start now|apply now|asap\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "  cbind(\n",
    "    essential,\n",
    "    desc_feats,\n",
    "    req_feats\n",
    "  )\n",
    "}\n",
    "\n",
    "features_batch <- prepare_features_batch(batch_data)\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# 4. APPLY SCALING USED IN TRAINING\n",
    "# -------------------------------------------\n",
    "features_scaled <- predict(preproc, features_batch)\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# 5. MODEL PREDICTION\n",
    "# -------------------------------------------\n",
    "probs_batch <- predict(xgb_model, newdata = features_scaled, type = \"prob\")\n",
    "\n",
    "# If caret returns numeric vector\n",
    "if (is.numeric(probs_batch)) {\n",
    "  probs_batch <- data.frame(No = 1 - probs_batch, Yes = probs_batch)\n",
    "}\n",
    "\n",
    "pred_batch <- ifelse(probs_batch$Yes >= 0.5, \"Yes\", \"No\")\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# 6. CREATE CLEAN OUTPUT (ONLY FRONTEND FIELDS + PREDICTION)\n",
    "# -------------------------------------------\n",
    "output_df <- batch_data[ , frontend_fields ]\n",
    "output_df$Prediction          <- pred_batch\n",
    "output_df$Probability_Fake    <- round(probs_batch$Yes, 4)\n",
    "output_df$Probability_Genuine <- round(probs_batch$No, 4)\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# 7. SAVE CSV FILES\n",
    "# -------------------------------------------\n",
    "write.csv(output_df, \"predictions_all_records.csv\", row.names = FALSE)\n",
    "write.csv(output_df[output_df$Prediction == \"Yes\",], \n",
    "          \"predictions_fake_only.csv\", row.names = FALSE)\n",
    "write.csv(output_df[output_df$Prediction == \"No\",],  \n",
    "          \"predictions_genuine_only.csv\", row.names = FALSE)\n",
    "\n",
    "cat(\"\\nðŸŽ‰ Batch Prediction Completed!\\n\")\n",
    "cat(\"ðŸ“ Saved: predictions_all_records.csv\\n\")\n",
    "cat(\"ðŸ“ Saved: predictions_fake_only.csv\\n\")\n",
    "cat(\"ðŸ“ Saved: predictions_genuine_only.csv\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
